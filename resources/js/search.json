[[{"i":"what-is-ezkl","l":"What is EZKL?","p":["ezkl is a library and command-line tool for doing inference for deep learning models and other computational graphs in a zk-snark. It enables the following workflow:","Define a computational graph, for instance a neural network (but really any arbitrary set of operations), as you would normally in pytorch or tensorflow.","Export the final graph of operations as an .onnx file and some sample inputs to a .json file.","Point ezkl to the .onnx and .json files to generate a ZK-SNARK circuit with which you can prove statements such as:","\"I ran this publicly available neural network on some private data and it produced this output\"","\"I ran my private neural network on some public data and it produced this output\"","\"I correctly ran this publicly available neural network on some public data and it produced this output\"","The rust API is also sufficiently flexible to enable you to code up a computational graph and resulting circuit from scratch. For examples on how to do so see the library examples section below.","In the backend we use Halo2 as a proof system.","For more details on how to use ezkl, we invite you to explore the docs and check out the repo!"]},{"i":"contributing","l":"Contributing \uD83C\uDF0E","p":["If you're interested in contributing and are unsure where to start, reach out to one of the maintainers:","dante (alexander-camuto)","jason (jasonmorton)","jseam (JSeam2)","lance (lancenonce)","More broadly:","Feel free to open up a discussion topic to ask questions.","See currently open issues for ideas on how to contribute.","For PRs we use the conventional commits naming convention."]}],[{"l":"Getting Started"},{"i":"building-the-project","l":"building the project \uD83D\uDD28","p":["Note that the library requires a nightly version of the rust toolchain. You can change the default toolchain by running:","After which you may build and install the library","If you want to build manually with cargo build, be sure to use the release flag as the debug build will result in slow proofs"]},{"i":"rust-docs","l":"Rust docs \uD83D\uDCD6","p":["Use cargo doc --open to compile and open the Rust documentation for ezkl in your default browser. We will also have a live link with our Rust documentation available soon."]}],[{"l":"Command Line Interface","p":["The ezkl cli provides a simple interface to load .onnx files, which represent graphs of operations (such as neural networks), convert them into a Halo2 circuit, then run a proof."]},{"i":"python-and-cli-tutorial","l":"python and cli tutorial \uD83D\uDC0D","p":["You can easily create an .onnx file using pytorch. For samples of Onnx files see here. For a tutorial on how to quickly generate Onnx files using python, check out pyezkl. You'll also need an input.json file with sample inputs and outputs of your model (Note: input shape is no longer needed since this is now inferred by the library).","Sample onnx files are also available in ./examples/onnx. To generate a proof on one of the examples, first build ezkl( cargo build --release) and add it to your favourite PATH variables, then generate a structured reference string (SRS):","We then set up the circuit to create a proving and verifying key for our circuit. You must provide the input.json (for proving and verifying) and network.onnx files.","This command generates a proof that the model was correctly run on private inputs (this is the default setting). It then outputs the resulting proof at the path specfifed by --proof-path, parameters that can be used for subsequent verification at --params-path and the verifier key at --vk-path:","We can then verify our generated proof with the verify command:","To display a table of the loaded onnx nodes, their associated parameters, set RUST_LOG=DEBUG or run:"]},{"l":"using pre-generated SRS","p":["Note that you can use pre-generated KZG SRS. These SRS can be converted to a format that is ingestable by the pse/halo2 prover ezkl uses by leveraging han0110/halo2-kzg-srs. This repo also contains pre-converted SRS from large projects such as Hermez and the perpetual powers of tau repo. Simply download the pre-converted file locally and point --params-path to the file.","Note: Ensure you download the files in raw format. As this will be more performant and is the serialization format ezkl assumes."]},{"i":"general-usage","l":"general usage \uD83D\uDD27","p":["Note: to get the full suite of cli capabilities you'll need to compile ezkl with the render feature ( cargo build --features render --bin ezkl). This enables the render-circuit command which can create .png representations of the compiled circuits. You'll also need to install the libexpat1-dev and libfreetype6-dev libraries on Debian systems (there are equivalents for MacOS as well).","bits, scale, and tolerance have default values. You can use tolerance to express a tolerance to a certain amount of quantization error on the output eg. if set to 2 the circuit will verify even if the generated output deviates by an absolute value of 2 on any dimension from the expected output. We also added percentage tolerance checks if you'd prefer to use a percent deviation of the output. Here's an examle of percent tolerance (we use -T for tolerance):","prove and mock, all require -D and -M parameters, which if not provided, the cli will query the user to manually enter the path(s).","The .onnx file can be generated using pytorch or tensorflow. The data json file is structured as follows:","For examples of such files see examples/onnx_models.","To run a simple example using the cli see python and cli tutorial above.","If the above commands get too heavy and it becomes difficult to track parameters across commands; ezkl also supports loading global arguments (those specified before a subcommand) from a .json file. This can be done using the RUNARGS environment variable. For instance:","For an example of such a file see examples/default_run_args.json:","Note that command-wide arguments can be specified using the EZKLCONF environment variable; which supercedes RUNARGS in priority ! This json includes both global level arguments and subcommand specific arguments. Usage is thus as such:"]}],[{"l":"Verifying On-Chain"},{"i":"verifying-with-the-evm-","l":"verifying with the EVM â—Š","p":["Note that the above prove and verify stats can also be run with an EVM verifier. This can be done by generating a verifier smart contract after generating the proof","Note that the .sol file above can be deployed and composed with other Solidity contracts, via a verify() function. Please read this document for more information about the interface of the contract, how to obtain the data needed for its function parameters, and its limitations.","The above pipeline can also be run using proof aggregation to reduce proof size and verifying times, so as to be more suitable for EVM deployment. A sample pipeline for doing so would be:","Also note that this may require a local solc installation, and that aggregated proof verification in Solidity is not currently supported. You can follow the SolidityLang instructions linked above, or you can use svm-rs to install solc. Here's how:","Install svm-rs:","Install a recent Solidity version (we use 0.8.17 in our implementation):","Verify your Solidity version:"]}],[{"l":"Examples","p":["This repository includes onnx example files as a submodule for testing out the cli.","If you want to add a model to examples/onnx, open a PR creating a new folder within examples/onnx with a descriptive model name. This folder should contain:","an input.json input file, with the fields expected by the ezkl cli.","a network.onnx file representing the trained model","a gen.py file for generating the .json and .onnx files following the general structure of examples/tutorial/tutorial.py.","TODO: add associated python files in the onnx model directories."]},{"i":"library-examples","l":"library examples \uD83D\uDD0D","p":["Beyond the .onnx examples detailed above, we also include examples which directly use some of our rust API; allowing users to code up computational graphs and circuits from scratch in rust without having to go via python.","The MNIST inference example using ezkl as a library is contained in examples/conv2d_mnist. To run it:","We also provide an example which runs an MLP on input data with four dimensions. To run it:"]}],[{"l":"Python bindings","p":["Python bindings are built for ezkl using PyO3 and Maturin. This is done so to allow users of ezkl to leverage on the rich Data Science ecosystem that Python has instead of using Rust only.","Check out our Jupyter Notebook example here"]},{"l":"production","p":["Production Python bindings are made available via pyezkl."]},{"l":"development","p":["To test the developmental Python bindings you will need to install Python3. ezkl only supports version of python where python =3.7.","Once python is installed setup a virtual environment and install maturin","You can now build the package for development and enable python bindings. The following command will install ezkl_lib into your local python environment.","Once done you will be able to access ezkl_lib as a python import as follows.","You may test if the existing build is working properly.","The list of python functions that can be accessed are found within src/python.rs"]}],[{"l":"Compiling to WASI","p":["The cli can also be compiled for the wasm32-wasi target (browser bindings with wasm32-unknown-unknown under Tutorials/WASMTutorial). To do so first ensure that wasm-pack is installed.","You can then run:","After adding the wasm32-wasi target, you can use wasm-pack to build ezkl for the wasm32-wasi target. The -Z flag helps us build unstable features.","Note: On Mac you may need to install llvm and clang using homebrew then explicitly set the CC and AR environment variables. For instance: AR=/opt/homebrew/opt/llvm/bin/llvm-ar CC=/opt/homebrew/opt/llvm/bin/clang wasm-pack build --bin ezkl --target wasm32-wasi -Z build-std=panic_abort,std. You can learn more about how to install these in the WASM tutorial.","You can then run the compiled .wasm file as you would the normal cli detailed above (just not the EVM related commands), by using wasmtime. This command runs ezkl help on wasmtime."]}],[{"l":"Compiling with wasmtime","p":["The cli can also be compiled to for wasm32-wasi target (browser bindings with wasm32-unknown-unknown coming soon). To do so first ensure that wasm-pack is installed.","You can then run:","Note: On Mac you may need to install llvm and clang using homebrew then explicitly set the CC and AR environment variables. For instance: AR=/opt/homebrew/opt/llvm/bin/llvm-ar CC=/opt/homebrew/opt/llvm/bin/clang wasm-pack build --bin ezkl --target wasm32-wasi","You can then run the compiled .wasm file as you would the normal cli detailed above (just not the EVM related commands), by using wasmtime."]}],[{"l":"Benchmarks","p":["We include proof generation time benchmarks for some of the implemented layers including the affine, convolutional, and ReLu operations (more to come).","To run these benchmarks:","This may take a long time.","To run a specific benchmark append one of affine, cnvrl, relu to the command. You can then find benchmarks results and plots in target/criterion. Note that depending on the capabilities of your machine you may need to increase the target time on the Criterion config. For instance:"]}],[{"l":"About ONNX"},{"i":"what-is-onnx","l":"What is ONNX?","p":["ONNX (Open Neural Network Exchange) is an open-source standard for representing deep learning models. It was developed to facilitate interoperability between various deep learning frameworks, such as TensorFlow, PyTorch, and Caffe2. ONNX provides a common file format that allows models trained in one framework to be used in another framework for inference, without the need for model conversion."]},{"i":"why-do-we-use-onnx","l":"Why do we use ONNX?","p":["ONNX is used for several reasons:","Easy Integration: ONNX files are used in ezkl to generate zk-SNARKS from individual operations (e.g. ReLU, Sigmoid, Softmax). The ONNX format makes it straight-forward to parse and separate layers for generating individual circuits.","Interoperability: ONNX enables developers to train models in one deep learning framework and use them in another for inference, without the need for conversion. This eases the process of deploying models and allows developers to use the best tools for each part of the development process.","Portability: ONNX provides a standardized format for deep learning models, making it easier to share models across different platforms and devices.","Optimization: ONNX-compatible tools and libraries, such as ONNX Runtime, can provide optimizations for specific hardware, leading to improved performance.","Ecosystem support: Many popular deep learning frameworks and tools, like TensorFlow, PyTorch, and Microsoft's ONNX Runtime, support ONNX, providing a broad range of options for developers."]},{"l":"How to create an ONNX file","p":["Check out our pyezkl repository to find detailed steps on generating an ONNX file."]}],[{"l":"Security","p":["Zero knowledge machine learning, particularly in blockchain applications, is still a nascent field and should be used with precaution. Because there have not been many production-ready projects, the potential attack vectors are mostly theoretical or unknown.","However, we ensure that if an ML model is secure, ezkl proofs will be sound and secure. Below we discuss best security practices for your neural networks and what we're doing on our end to ensure our proofs are secure."]},{"i":"aiml-security","l":"AI/ML Security","p":["There are several types of adversarial attacks on neural networks. Gaussian Noise Injection, Data poisoning, Membership Inference Attacks(MIAs), and more are attack vectors that adversaries can use to corrupt your ouputs. MIAs and others like it are especially hazardous when the aim of using zkml is to keep the model and its training data private.","Adversarial Training involves training your model with adversarial data so that edge cases are expected and accounted for. CleverHans is a useful tool for discovering potential vulnerabilities in your model. For best security results, have an idea of the overall threat model of your neural net and its potential inputs."]},{"l":"ZK Security","p":["The goal of zero knowledge proof systems is to construct complete, sound proofs. Completeness is the highly probable assurance that any valid proof will verify. Soundness is the quality of the verifier (or parties representing the verifier) knowing that if a proof passes, it is more than likely a true statement. In some cases, such as those in underconstrained circuits, bad proofs can be generated that fool the verifier into passing a false statement. In this case, the vulnerability is not in the machine learning model itself, but in the SNARK constructed by ezkl.","In this case, we would deeply appreciate an issue or discussion regarding the bad proof. We will respond with alacrity."]},{"l":"EZKL Security Tooling","p":["We want to provide you with the best means of mitigating the potential of an attack on the SNARK of your model. This is why we are making security tools that allow you to test the robustness of your model."]},{"l":"Fuzzing","p":["ezkl supports fuzzing over your model's edge inputs to test for potential vulnerabilities. Use your input.json and network.onnx files to run:","Be sure to replace num-runs with the amount of fuzz testing rounds you want to do along with other parameters you are using to generate your circuit.","Thank you for using ezkl; please contact us if you have any security resources that should be included in this documentation."]}],[{"l":"FAQ"},{"i":"what-programming-languages-and-frameworks-does-ezkl-support","l":"What programming languages and frameworks does ezkl support?","p":["ezkl does not require application of a programming language. You may want to use Python to create a neural network and export it with pyezkl, but though the library is built with Rust, you do not need to use Rust."]},{"i":"do-i-need-to-know-rust-before-getting-started-with-ezkl","l":"Do I need to know Rust before getting started with ezkl?","p":["No, Rust is not a requirement to use the library. As long as you have the ONNX file and proper input & output format of the model, you can use ezkl."]},{"l":"Technical"},{"i":"why-is-the-gen-srs-step-is-stalling","l":"Why is the gen-srs step is stalling?","p":["Generating a structured reference string takes a considerable amount of time and memory. Make sure your machine has enough memory available and wait for the process to finish."]},{"i":"can-i-use-ezkl-with-other-machine-learning-frameworks-like-tensorflow-pytorch-or-scikit-learn","l":"Can I use ezkl with other machine learning frameworks like TensorFlow, PyTorch, or Scikit-learn?","p":["All ezkl requires is an onnx file and a JSON configuration of mock inputs and outputs of the neural network."]},{"i":"how-fast-is-ezkl","l":"How fast is ezkl?","p":["Feel free to run cargo bench on your machine to see what the benchmarks are for your hardware."]},{"i":"do-i-need-to-deploy-a-verifier-smart-contract-to-use-ezkl","l":"Do I need to deploy a verifier smart contract to use ezkl?","p":["No, we recently integrated a WASM verifier that you can use to verify proofs from your web application. You can also use the EVM verifier to verify proofs locally."]},{"i":"errors","l":"Errors:"},{"i":"error-verifyerror","l":"Error: VerifyError","p":["A VerifyError is thrown when the Mock prover fails due to a mismatched shape problem in the model. Please verify that your input.json inputs and outputs match those of your .onnx file."]},{"i":"error-dimmismatch","l":"Error: DimMismatch","p":["A DimMismatch error is thrown when there is a mismatch in the lengths of the tensor operands during circuit construction."]},{"i":"error-lookupinstantiation","l":"Error: LookupInstantiation","p":["This error is thrown when there is an error during the creation of a lookup table"]},{"i":"error-tablealreadyassigned","l":"Error: TableAlreadyAssigned","p":["A TableAlreadyAssigned Error is thrown when ezkl attempts to initialize a lookup table that has already been initialized"]},{"i":"error-unsupportedop","l":"Error: UnsupportedOp","p":["An UnsupportedOp Error is thrown when there is an operation in the ONNX file that ezkl cannot yet handle. Please look at the supported operations under src/circuit/ops to get an idea of what operations ezkl can handle."]},{"i":"error-pyvalueerror","l":"Error: PyValueError","p":["This is a pyo3 error that occurs when a data type fails to be extracted from Python to Rust. Please make sure you are passing the correct data types when utilizing the python bindings."]},{"i":"error-invalidlookupinputs","l":"Error: InvalidLookupInputs","p":["InvalidLookupInputs is thrown when the wrong inputs were passed to a lookup node."]},{"i":"error-invaliddims","l":"Error: InvalidDims","p":["InvalidDims is thrown when there is a shape mismatch in circuit construction. Invalid dimensions were used for a node with the given index and description."]},{"i":"error-wrongmethod","l":"Error: WrongMethod","p":["This error means that the wrong method was called to configure a node with the given index and description"]},{"i":"error-missingnode","l":"Error: MissingNode","p":["MissingNode is thrown when a requested node is missing in the graph with the given index"]},{"i":"error-opmismatch","l":"Error: OpMismatch","p":["OpMismatch is thrown when an unsupported method was called on a node with the given index and description"]},{"i":"error-unsupportedop-1","l":"Error: UnsupportedOp","p":["UnsupportedOp is thrown when there is an operation in the onnx graph that isn't supported by ezkl"]},{"i":"error-missingparams","l":"Error: MissingParams","p":["MissingParams is thrown when a node has missing parameters; please check the parameters in your model's operations"]},{"i":"error-misformedparams","l":"Error: MisformedParams","p":["MisformedParams is thrown when a node has misformed parameters; the error can stem from erroneous padding height and width dimensions, wrong kernel / data format, dilations that are not uint type, and more."]},{"i":"error-visibility","l":"Error: Visibility","p":["This error is typically thrown when no public variables are passed to the circuit configuration function"]},{"i":"error-nonconstantdiv","l":"Error: NonConstantDiv","p":["ezkl only supports divisions by constants"]},{"i":"error-nonconstantpower","l":"Error: NonConstantPower","p":["ezkl only supports constant exponents"]},{"i":"error-rescalingerror","l":"Error: RescalingError","p":["This error is thrown when attempting to rescale inputs for an operation"]},{"i":"error-modelload","l":"Error: ModelLoad","p":["This error is thrown when a model fails to load; please check your onnx file for missing connections / unsupported layers. We suggest using Netron to view onnx files."]},{"i":"error-packingexponent","l":"Error: PackingExponent","p":["PackingExponent is thrown when the scale for packing tensor values is too large. Keep the exponent under the logarithm (with your chosen base) of i128::MAX(about 38 for base 10, about 88 for base e)."]}],[{"l":"WASM Tutorial","p":["WASM storm"]},{"l":"Getting Started","p":[".gitignore","After this step, make sure you have access to the PATH for both clang and llvm. We'll be using environment variables such as CC=/opt/homebrew/opt/llvm/bin/clang for the remainder of the project.","Another thing we need before we get our .wasm file is LLVM. LLVM is a compiler tool that will help us use libraries that are essential for compiling our Rust ezkl code to a WASM binary fit for wasm32-unknown-unknown. You can get the latest release here(especially for Windows users) or install it with a package manager:","ezkl_lib_bg.wasm","ezkl_lib_bg.wasm.d.ts","ezkl_lib.d.ts","ezkl_lib.js","First, we need to add the wasm32-unknown-unknown target to our rustup configuration. wasm32-unknown-unknown is is a target for creating WebAssembly binaries. The wasm32 part represents the platform (WASM 32 bit in our case). The first unknown specifies the operating system we are building on. We want to build on any operating system since we're just building on browser. The second unknown refers to the target's standard library (Rust/C++ std), but with WASM, we won't be using one. We add this as a target with:","If something goes wrong, be certain that the paths to your llvm-ar and clang libraries are correct. Also make sure wasm-pack is installed and that your .cargo/config file in ezkl looks like this:","Install wasm-pack","It is useful to have a verifier on a blockchain. However, sometimes you just want to generate and verify proofs in the browser. Thankfully, ezkl supports a WASM environment that you can use to generate proofs and verify them in-browser. For those who are unfamiliar, here is a good resource on WASM and here you can find the functions we define for ezkl's WASM interface. Let's get started!","Linux","Mac: You can use Homebrew to install llvm. This library comes with clang, which we'll also need.","Make sure that you supply the correct paths for llvm-ar and clang (AR and CC). You can use brew info llvm on Mac or dpkg -L llvm for Linux.","Note that you should be on Rust's nightly release channel when interacting with ezkl.","Now, navigate to your fork or branch of ezkl and install the WASM server runner:","package.json","README.md","This command will generate a directory called pkg in our root ezkl directory. Within it, you will find these files:","With this, we're finally able to compile our .wasm file! You can do that with this command:"]},{"l":"Creating a frontend","p":["add in setup steps We'll be using the ezkl library to pass in input data, the proving key, the serialized circuit, the serialized circuit parameters, and our polynomial commitment scheme paramenters to our prove_wasm function. Additionally, we will pass the proof, the verify key, the serialized circuit parameters, and the polynomial commitment scheme parameters to our verify_wasm function. It is important to note that you will have a lot of this information after you create a circuit with ezkl. Feel free to store them in your project (perhaps .gitignore-ing them). Let's begin.","And thus, we have a WASM prover and verifier that you can use for your zkml project without having to worry about the blockchain! Feel free to check out the source code and build your own zkml applications with this simple interface. Thank you for reading, and thank you for using ezkl.","At the end of the interaction, your screen should look something like:","circuit_params_ser: circuit parameters (circuit.params)","circuit_ser: circuit (network.onnx)","copy your new pkg directory into the project","create an index.html and paste this starter code in:","data: input data (input.json)","Finally, run the setup step in ezkl (WASM support for this coming soon) and upload the files to your Prove function. The ordering for Prove(from left to right) is:","Make a new directory for your project.","Now that we have the wasm-pack package, we can build a simple frontend that uses its exports to prove and verify models (we would love to see projects using this in more intricate ways).","params_ser: commitment scheme parameters (kzg.params)","pk: proving key (pk.key)","proof_js: proof (proof.pf)","Run a simple http server such as python3's:","This script generates a simple HTML frontend with fields to pass in files for our input fields (we'll upload them from our ezkl directory). It also calls the ezkl_lib.js folder in our pkg to fetch the exported prove_wasm, verify_wasm, and init_panic_hook functions.","This will prompt you to download a file called result. result is a binary file of the generated proof. Note that this step may take time. After result has been downloaded, upload the file to the first value of the Verify function. The ordering for Verify(from left to right) is:","True or False should appear as the result for the Verify function.","verification","vk: verifier key (vk.key)"]}]]