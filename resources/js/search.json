[[{"i":"what-is-ezkl","l":"What is EZKL?","p":["ezkl is a library and command-line tool for doing inference for deep learning models and other computational graphs in a zk-snark. It enables the following workflow:","Define a computational graph, for instance a neural network (but really any arbitrary set of operations), as you would normally in pytorch.","Export the final graph of operations as an .onnx file and some sample inputs to a .json file.","Point ezkl to the .onnx and .json files to generate a ZK-SNARK circuit with which you can prove statements such as:","\"I ran this publicly available neural network on some private data and it produced this output\"","\"I ran my private neural network on some public data and it produced this output\"","\"I correctly ran this publicly available neural network on some public data and it produced this output\"","ezkl can be used directly from Python; see this colab notebook and the python bindings docs. What is EZKL?","The rust API is also sufficiently flexible to enable you to code up a computational graph and resulting circuit from scratch. For examples on how to do so see the library examples in the repo. In the backend we use Halo2 as a proof system. For more details on how to use ezkl, we invite you to explore the docs and check out the repo!"]},{"l":"The life cycle of a proof","p":["There are three steps in the life of an ezkl proof: Setup, Prove, and Verify. Each step is generally performed by a different party."]},{"l":"Setup","p":["Setup is invoked with ezkl setup at the cli or ezkl.setup() in Python. It defines what consitutes a proof and how that proof will be verified, setting the rules of the game. Setup is performed by the application developer, who then deploys the resulting artifacts to production.","The inputs to setup are:","the model (as an onnx file)","the \"params,\" (structured reference string) which are a common, public piece of cryptographic data shared among proofs of the same size","various flags, settings, and options for tuning and added functionality","The outputs of setup are:","the proving key","the verification key","the circuit params: serialized flags, settings, and options, and a few numbers that describe the shape of the resulting circuit"]},{"l":"Prove","p":["Prove, invoked with ezkl prove at the cli or ezkl.prove() in Python, is called by the prover, often on the client. The prover is making a claim that it knows some inputs (which might include model parameters), such that when the model (chosen during setup) is run on them, produces certain outputs. The prove function computes a cryptographic proof of that claim, which can then be believed by any verifier.","The inputs to prove are:","the data (an input.json file) containing the claim: an input, output pair such that model(input) = output (this output can be produced using the forward command)","the model (as an onnx file)","the proving key","the params (structured reference string)","the circuit params","The outputs of prove are:","the proof file"]},{"l":"Verify","p":["Verify is invoked with ezkl verify at the cli, ezkl.verify() in Python, or from an Ethereum smart contract using the EVM verfier. It checks the correctness of the cryptographic proof produced by the prover.","The inputs to verify are:","the proof file","the verification key","the circuit params","the params (structured reference string)","ezkl can also produce an EVM or wasm verifier which takes only the proof as input."]},{"i":"contributing","l":"Contributing \uD83C\uDF0E","p":["If you're interested in contributing and are unsure where to start, reach out to one of the maintainers on our Telegram group.","More broadly:","Feel free to open up a discussion topic to ask questions.","See currently open issues for ideas on how to contribute.","For PRs we use the conventional commits naming convention."]}],[{"l":"Getting Started"},{"i":"building-the-project","l":"building the project \uD83D\uDD28","p":["Ezkl is built in rust. First install rust, e.g. by","then download the repo and enter the directory","We require a nightly version of the rust toolchain. You can change the default toolchain by running:","After which you may build and install the library","If you want to build manually with cargo build, be sure to use the release flag as the debug build will result in slow proofs","Note: To render your model circuits, you'll need to compile ezkl with the render feature ( cargo build --features render --bin ezkl). This enables the render-circuit command which can create .png representations of the compiled circuits. You'll also need to install the libexpat1-dev and libfreetype6-dev libraries on Debian systems (there are equivalents for MacOS as well)."]},{"i":"rust-docs","l":"Rust docs \uD83D\uDCD6","p":["Use cargo doc --open to compile and open the Rust documentation for ezkl in your default browser."]},{"l":"Things to consider","p":["This section is meant to give our users some warnings and precautions about using ezkl."]},{"l":"Quantization","p":["In order to create a SNARK of a neural network, we must quantize the model parameters. In ML, parameters are almost always floating point numbers. In ezkl, we transform these to field elements so that we can use the zero knowledge proving system appropriately. Though we preserve as much precision as possible with our --scale flag (discussed more under the Commands section), outputs can still have some margin of error that should be accounted for."]}],[{"l":"Command Line Interface","p":["The ezkl cli provides a simple interface to load .onnx files, which represent graphs of operations (such as neural networks), convert them into a Halo2 circuit, then run a proof."]},{"i":"cli-tutorial","l":"CLI tutorial \uD83D\uDC7E","p":["You can easily create an .onnx file using pytorch. For samples of Onnx files see here. For a tutorial on how to quickly generate Onnx files using python, check out pyezkl. You'll also need an input.json file with sample inputs and outputs of your model (Note: input shape is no longer needed since this is now inferred by the library).","Sample onnx files are also available in ./examples/onnx."]},{"l":"Initializing the project","p":["To generate a proof on one of the examples, first install ezkl Command Line Interface then generate a structured reference string (SRS):","Note that this SRS is for testing purposes only.","Put a model file ( network.onnx) and input file ( input.json) into your working directory, e.g. with something like:"]},{"l":"Setting circuit parameters","p":["Our circuit is configured with the settings.json file. This is created with the gen-settings command (replace network.onnx with the relative path of one of the example's .onnx files):","This will produce a settings.json file you can use for your circuit. However, you can fine-tune your circuit to optimize for accuracy or CPU/memory usage with the calibrate-settings command:","In this example, we set the --target to \"resources\" so that we can optimize for CPU and memory usage. The other option is \"accuracy\", which optimizes for accuracy given the fixed point representation of the input model. Our circuit parameters are generated, then saved to settings.json. You can customize this file and even change the way it's generated. Learn more about gen-settings& calibrate-settings in the Commands section."]},{"l":"Creating the circuit","p":["Now, we use setup to create a proving and verifying key for our circuit, using the SRS, our circuit params, and the .onnx file.","This creates the verification key, proving key, and circuit params in the locations you specify. You can view the options associated to a subcommand like setup by typing"]},{"l":"Making a proof","p":["Next we will generate a proof that the model was correctly run on private inputs (this is the default setting). It then outputs the resulting proof at the path specfifed by --proof-path."]},{"l":"Verification","p":["We can then verify our generated proof with the verify command:"]},{"l":"Visualizing our model","p":["To display a table of the loaded onnx nodes, their associated parameters, set RUST_LOG=DEBUG or run:"]},{"l":"Using a pre-generated SRS","p":["Note that you can use pre-generated KZG SRS. These SRS can be converted to a format that is ingestable by the pse/halo2 prover ezkl uses by leveraging han0110/halo2-kzg-srs. This repo also contains pre-converted SRS from large projects such as Hermez and the perpetual powers of tau repo. Simply download the pre-converted file locally and point --srs-path to the file.","Note: Ensure you download the files in raw format. As this will be more performant and is the serialization format ezkl assumes."]},{"i":"general-usage","l":"General usage \uD83D\uDD27","p":["This is a comprehensive list of the commands and flags you can use with ezkl. Learn more about the Commands here: Command Line Interface","And the flags (RunArgs) here: Command Line Interface","prove and mock both require -D and -M parameters.","The .onnx file can be generated using pytorch or tensorflow.","For examples of such files see examples/onnx_models."]}],[{"l":"Commands"},{"l":"ezkl Commands","p":["The ezkl CLI is the gateway to ezkl. In this Tutorial, we will explain in-depth the core ezkl commands along with the other commands you can use to broaden your model SNARKing toolkit. Feel free to build ezkl on your own machine and follow along with the examples. For each of these, we will be using the 1l_sigmoid example under examples/onnx."]},{"l":"GenSRS","p":["In PLONKish proving systems such as those provided by halo2, a polynomial commitment scheme is necessary to evaluate polynomials at certain points without revealing the original function. In order to use a polynomial commitment scheme, we need to set up a structured reference string (SRS). ezkl enables you to create a SRS that will define the size of the circuit (number of rows in particular) and that you will use as public parameters to your SNARK (so that the prover and verifier can communicate clearly and honestly). Use this command to generate a KZG structured reference string with (for example) 17 rows.","This sets up a SRS that the prover can use to commit and the verifier can use to evaluate in a file called 17.srs.","Note: The SRS generated by gen-srs is not meant to be used in production. For production usage, use a pre-generated SRS from a ceremony such as those at han0110/halo2-kzg-srs, or the Ethereum proto-danksharding ceremony. You can download these in raw format (not canonical format) and use it with ezkl here.","Note: Downsizing an SRS is time consuming, so if you generate a logrows=20 SRS and the circuit uses logrows=17, the prove command will spend most of its time downsizing your 20.srs from 20 to 17. Once you know the logrows you need, use a file of that size for max speed."]},{"l":"Generate Settings","p":["For ezkl to compute a snark, it needs some settings to determine how to create the circuit. You can create settings with the gen-settings command.","For example, this is the file generated from our CLI tutorial example using sigmoid:","By default the settings file will be called settings.json.","settings.json:","Let's say our circuit was much larger; we need to bump logrows to 23. We can add a flag to our original command to specifiy this (using -O to give the output a different name):","This produces circuitK23.json:","Notice logrows is now 23. You can do this for any other parameter for custom circuits. The .json file can also be manually edited to tweak the choices"]},{"l":"Calibrate Settings","p":["There are a lot of adjustable knobs (such as bits, scale, and logrows) in ezkl that let you trade off between prover and verifier resources, accuracy, and control other parts of the zkp. While you are free to choose these manually with cli parameters passed to gen-settings, we recommend fine-tuning with the automatic calibration provided by the calibrate-settings command. This modifies your settings.json file with a suggested choice of circuit parameters:","You can also set the --target to \"accuracy\" if you want to optimize for numerical accuracy rather than CPU and memory performance. The default is set to \"resources\". The largest tradeoff for these two is in the size of logrows and scale. With a higher scale, floating point numbers are interpreted more accurately. With a smaller logrows, a smaller, less memory-intensive circuit is generated.","For example, after running the same command with --target set to accuracy, we get a larger value for scale amongst other changes:","settings.json:","Note: You can still use the generic RunArgs for mock and forward(e.g. ezkl mock --logrows=22 --bits=21 rather than ezkl mock --settings-path circuit.json). However, --settings-path takes priority."]},{"l":"Setup","p":["Along with our SRS and circuit parameters, we need two other elements to generate a proof: a proving key and a verifying key. You will get both by running ezkl's setup command. We need our proving key to generate proofs; we need our verifying key to verify proofs from the corresponding proving key.","Run this command to set up your proving and verifying keys:","You should now have files called vk.key and pk.key in the root of your project. You can also specify different paths for these outputs with --vk-path=altvk.key --pk-path=altpk.key"]},{"l":"Prove","p":["Now that we have all the parameters, it's time to generate our proof! The proof will likely take the longest to generate. This is because most of the heavy work of setting constraints and lookups takes place here.","In a typical zk application, the proof will be generated by the client, then verified on a blockchain or server. To make this easier, ezkl provides WASM bindings for prove that you can use to generate proofs in-browser. You can check out our WASM tutorial to see how.","Here is the command for generating a proof:","This will create a proof file called model.proof that anyone can later use to verify your model was run correctly on the input."]},{"l":"Verify","p":["Verification can be done from the CLI, in WASM, or on a blockchain. Verification will require the commitment scheme parameters, the circuit parameters, the verifying key, and, of course, the proof. When verifying with a smart contract, however, the verifying key and circuit/commitment params are baked into the smart contract; this means only the public parameters will be passed as calldata along with the proof. The command for verifying from the CLI is:","This will return whether your proof has successfully verified or not. Feel free to refer to the WASM tutorial to verify with WASM and the Verifying On-Chain section to verify with an EVM smart contract.","Note that these are not the only operations that can be performed by ezkl. You can also run a Mock proof to see if a proof will verify, or run the Table command to see a table of all your onnx operations that your SNARK will consist of. The table command is helpful in determining if ezkl knows how to snark your model. You can also run Fuzz to fuzz test your SNARK on random inputs. Even our EVM commands can take in RunArgs to specify how an evm verifier will be created. Let's look into the rest of these in detail."]},{"l":"Mock","p":["When you're testing a model, you may not want to run setup and prove with each iteration. ezkl provides a simple alternative with mock, where you can convert your model to constraints and run the inputs tosee if a proof can be generated. This saves time when testing new iterations of models with potential issues. Here is the command for mock:","Mock is basically checking that constraints that your model has been translated into are satisfied, without doing any of the subsequent cryptographic heavy lifting to produce a proof."]},{"l":"Forward","p":["Sometimes you want to run a forward pass of ezkl's quantized version of your model on some input data to generate the outputs it will be able to prove. ezkl also supports a forward pass function called forward:","This produces a file called new_input in our examples/onnx/1l_sigmoid directory. It is the provided input model, with the outputs replaced by what the quantized model will produce after a forward pass. You may need it for example if the original input.json file you produced was a dummy file that did not have correct outputs. We run it automatically in the export function in the Python version of ezkl."]},{"l":"Table","p":["ezkl's table command enables users to get their model's operations, inputs, and outputs in an intuitive format. Calling this command:","will produce a table that looks like:","You can use table with your model to know exactly which operations your model uses. If the operation is unsupported, you may see an Unknown in the table, and get a warning. This means the op isn't available in ezkl, and you should file an issue to request its implementation."]},{"l":"Render","p":["halo2 provides a service you can use to render a .png of your circuit layout, which can be useful in debugging. First install the binaries with the render feature enabled:","Then, run this command:","This will render our circuit as a file named render.png in our examples/onnx/1l_sigmoid directory.","image-20230608155046296","In this photo,","Pink columns represent advice, or private, values","White columns represent instance, or public, values","Purple/blue columns represent fixed, or constant, values (lookups as well)","Green areas represent regions in our circuit","These renders are great for finding ways to optimize your circuit (perhaps lowering the number of bits per cell or using more rows)."]},{"l":"Aggregate","p":["This step is described briefly in the Verifying On-Chain section. Here, we'll describe aggregate with more detail.","We can aggregate multiple proofs into one with the aggregate command. Let's make two new circuits: one that produces a proof called model.proof and another that produces a proof called model1.proof. In aggregation, we want to use a large circuit because we're dealing with multiple proofs. Let's set up a SRS of size k=23:","Now, let's say we want to aggregate a conv circuit and a relu circuit. We can set up the parameters for these different circuits with gen-circuit-params. For the sake of the example, let's set one to optimize for accuracy and another to optimize for resources:","and for RELU:","Now, we can create our proof keys with setup(Note: be sure to use the same KZG parameters for all the circuits you plan to aggregate):","We then prove them (we'll run with RUST_LOG=debug to fetch our allocated constraints:","Now, we can aggregate the proofs:","This creates one proof that simultaneously proves both our conv and relu circuits as long as we pass both proofs and verifying keys in. The bad news is that computing an aggregation takes a lot of memory and time right now; this proof will probably take about four or five minutes."]},{"l":"VerifyAggr","p":["Now, we can verify our aggregated proof with:","This should return verified: true. You can learn more about aggregation here."]},{"l":"Fuzz","p":["You can learn more about fuzz in the Security section under EZKL Security Tooling."]}],[{"l":"RunArgs","p":["RunArgs are the fine-tuning parameters that give you more control over various aspects of ezkl. The majority of them have default values, so you typically don't see them in our basic instructions. This section will show you the various RunArgs you have at your disposal and how you can use them. To begin, here is a list of all the RunArgs we support and their flags (you can also take a look at these with ezkl setup --help):","Tolerance: -T| --tolerance","Scale: -S| --scale","Bits: -B| --bits","Logrows: -K| --logrows","Batch Size: --batch-size","Input Visibility: --input-visibility","Output Visibility: --output-visibility","Param Visibility: --param-visibility","Pack Base: --pack-base","Allocated Constraints: --allocated-constraints","Let's go over each in detail with examples. Again, we'll be using the 1l_sigmoid example under examples/onnx.","Note: We use \"computational graph\" and \"neural network\" interchangeably. This is due to the fact that ezkl can be used for making SNARKs of any computational graph including neural networks. You can think of \"computational graph\" as your model in .onnx format."]},{"l":"Tolerance","p":["Sometimes, quantization can throw off the output of our computational graph. We need to quantize to represent the model using the finite field of our proof system, but you might want to explictly tolerate a small range of values in your output when verifying. For example, let's say we are using a sigmoid layer with 2 values. The output should be [0.5,0.5](would be whole numbers depending on scale, using decimals for simplicity), but due to quantization, the SNARK's output is [0.4, 0.6]. You know that this result is just from quantization, so you want to allow more values than strictly 0.5 and 0.5 to appear in the output. This is where percent tolerance comes in. You can set the tolerance for error on model outputs so that the proof verifies on outputs that aren't exactly what you're expecting. You can use it like this:","This will give you a 1% tolerance on your outputs for this setup."]},{"l":"Scale","p":["ezkl quantizes a floting point value to a fixed point value by multiplying by 2^{scale} and rounding. Then the numerator is stored. The default scale is 7. When two numerators of scale 7 are mutiplied, you get a number of scale 14. Scale can be adjusted with -S or --scale:"]},{"l":"Bits","p":["Bits is the number of bits used in ezkl's lookup tables for nonlinearities. The default is 16. We can adjust it with the -B or --bits flag here:","Scale and bits are related. Typically we want bits to be twice scale, plus a margin of error (of perhaps 2 or 3), since two scale 7 numbers multiplied become scale 14, and then adding several of them we get to an even larger scale. That's why the default bits is twice the default scale plus 2. ezkl will give some warnings and suggestions if your scale and bits are off."]},{"l":"Logrows","p":["The logrows argument is the base 2 logarithm of the number of rows that are in our halo2 circuit. The default is 17. It cannot exceed the value of k in our structure reference string. You can read more about SRS in the first part of the Commands section. Bits must be at most one less than logrows (e.g. 16 when logrows is 17). Let's say that when using gen-srs we created a SRS of size 23:","This means we can setup circuits of any size less than or equal to that. Let's set up a circuit with 2^ 22 rows:"]},{"l":"Batch Size","p":["Typically in machine learning, models are trained and tested on batches of data. Perhaps you want to prove that a model was run on a batch of data rather than a single input batch. You can do this with the --batch-size flag (default is 1)."]},{"l":"Input Visibility","p":["Set this flag to public with --public-inputs=public(default private) if you want your inputs to be public instance variables in the halo2 circuit. Set it to hashed if you want the hash of your inputs to be public (with Poseidon). This can be useful for proving the validity or provenance of input data without necessarily making it public."]},{"l":"Output Visibility","p":["Set this flag to private with --public-outputs=private(default public) if you want your outputs to be private variables in the circuit. By default, outputs are public. You can also set this to hashed if you want your outputs hashed."]},{"l":"Param Visibility","p":["Set this flag to public(default private) with --public-params=public if you want your circuit parameters to be public. You can also hash these by using hashed. These will give you the opportunity to prove you're using certain parameters to certain individuals, but not the public."]},{"l":"Pack Base","p":["Sometimes, especially when verifying with the EVM, we want our outputs to take as little space as possible. --pack-base allows you to set a base to pack a tensor into an integer using powers of that base, like writing [1,2,3] as 321 in base 10."]},{"l":"Strategy","p":["In the Commands section, we used an example of proof aggregation to aggregate two proofs into one. You'll notice that the --strategy we used is called accum. The other option for --strategy is single(the default). These are used to specify the proving strategy. If we are proving a single circuit, we can leave this alone. If we are proving with aggregate, use the accum strategy."]},{"l":"Allocated Constraints","p":["Let's say you know the number of constraints from your model because you've generated a proof from it before. To save a bit of compute, you can use --allocated-constraints to specify how many constraints your circuit uses so that ezkl doesn't have to calculate this. For example, let's say my model uses 5 constraints. By setting --allocated-constraints to 5, I save my prover compute and time by not having to run the dummy layout pass to compute this with each proof generation. It could be very useful for in-production SNARKs that need to shave off every second of proof generation time.","By running ezkl prove, you can find the number of constraints your circuit has in INFO:","img"]}],[{"l":"Parameters"},{"l":"ezkl Parameters","p":["Each command in the ezkl CLI requires certain parameters to execute."]},{"i":"xsrs","l":"x.srs","p":["As discussed in the Commands section, we use gen-srs to create a polynomial commitment scheme parameters file x.srs(where x is logrows). These parameters are required in:","setup","prove","verify","aggregate","create-evm-verifier"]},{"i":"inputjson","l":"input.json","p":["The input.json file represents the model inputs and outputs. Previously, the model's input shape (e.g. [1, 28, 28]) was required, but now ezkl can infer the shape just from the inputs. This JSON object is what you will use to pass arbitrary inputs to your model. If you have a photo, you need to transform it to the appropriate shape for your model. If your model's input is [1, 28, 28] and you have an RGB photo with 1080x1080 pixels, you need to grayscale (channels go from 3 to 1) and resize the pixels (downscale 1080 to 28) so that your model can ingest the data properly.","ezkl takes a longer time to prove models with larger inputs. This means that using high quality images may take a while or run out of memory when generating a circuit. Here are the commands that require input.json:","prove","mock","forward","The data .json file is structured as follows:"]},{"i":"circuitjson","l":"circuit.json","p":["The circuit parameters are not at all related to the commitment scheme parameters. The circuit parameters are generated with gen-circuit-params and are used to assist in the construction of a Model Circuit. They include the RunArgs, the Visibility parameters, the potential number of the constraints in the circuit, and more. The commands that require circuit.json are:","setup(just provide the path to write the circuit parameters to)","prove","verify","aggregate(all the params of the circuits you want to aggregate)","create-evm-verifier","forward(can also use generic RunArgs)","mock(can also use generic RunArgs)"]},{"i":"networkonnx","l":"network.onnx","p":["ONNX(Open Neural Network Exchange) is an open-source standard for representing deep learning models. It was developed to facilitate interoperability between various deep learning frameworks, such as TensorFlow and PyTorch. ONNX provides a common file format that allows models trained in one framework to be used in another framework for inference, without the need for model conversion.","ONNX is used for several reasons:","*Easy Integration*: ONNX files are used in ezkl to generate zk-SNARKS from individual operations (e.g. ReLU, Sigmoid, Softmax). The ONNX format makes it straight-forward to parse and separate layers for generating individual circuits.","*Interoperability*: ONNX enables developers to train models in one deep learning framework and use them in another for inference, without the need for conversion. This eases the process of deploying models and allows developers to use the best tools for each part of the development process.","*Portability*: ONNX provides a standardized format for deep learning models, making it easier to share models across different platforms and devices.","*Optimization*: ONNX-compatible tools and libraries, such as ONNX runtimes, can provide optimizations for specific hardware, leading to improved performance.","*Ecosystem support*: Many popular deep learning frameworks and tools, like TensorFlow, PyTorch, and Microsoft's ONNX Runtime, support ONNX, providing a broad range of options for developers.","Check out our Python documentation and pyezkl repository to find detailed steps on generating an ONNX file. Here are the commands that require network.onnx:","setup","prove","mock","forward","table","render"]},{"i":"pkkey","l":"pk.key","p":["The Proving key for a circuit might be saved as pk.key. It is used to generate proofs and derive the verifying key. The commands that require pk.key are:","setup(path to write it to)","prove","aggregate"]},{"i":"vkkey","l":"vk.key","p":["The Verifying key for a circuit might be saved as vk.key. It is used to verify proofs created with the corresponding Proving Key. The commands that require vk.key are:","setup(path to write it to)","verify","aggregate","verify-aggr","create-evm-verifier"]},{"i":"modelproof","l":"model.proof","p":["The proof that is generated for a circuit might be called model.proof or network.pf. It is the actual proof that your verifier will use to verify proofs of your circuit. Typically this proof is generated by the client and verified by a blockchain, server, or another client. ezkl provides you with an assortment of tools for verifying the proofs you generate. Please submit an issue if you have any ideas for more platforms we should be looking to build verifiers on! Here are the commands that require a proof (or path to it):","prove(path to write it to)","aggregate","verify","verify-evm"]}],[{"l":"Verifying On-Chain"},{"i":"verifying-with-the-evm-","l":"verifying with the EVM ◊","p":["Verification can also be run with an EVM verifier. This can be done by generating a verifier smart contract after performing setup.","Note that the .sol file above can be deployed and composed with other Solidity contracts, via a verify() function. Please read this document for more information about the interface of the contract, how to obtain the data needed for its function parameters, and its limitations.","The above pipeline can also be run using proof aggregation to reduce the final proof size and the size and execution cost of the on-chain verifier. A sample pipeline for doing so would be:","Also note that this may require a local solc installation, and that aggregated proof verification in Solidity is not currently supported. You can follow the SolidityLang instructions linked above, or you can use svm-rs to install solc. Here's how:","Install svm-rs:","Install a recent Solidity version (we use 0.8.20 in our implementation):","Verify your Solidity version:"]}],[{"l":"Examples","p":["This repository includes onnx example files as a submodule for testing out the cli.","If you want to add a model to examples/onnx, open a PR creating a new folder within examples/onnx with a descriptive model name. This folder should contain:","an input.json input file, with the fields expected by the ezkl cli.","a network.onnx file representing the trained model","a gen.py file for generating the .json and .onnx files following the general structure of examples/tutorial/tutorial.py.","TODO: add associated python files in the onnx model directories."]},{"i":"library-examples","l":"library examples \uD83D\uDD0D","p":["Beyond the .onnx examples detailed above, we also include examples which directly use some of our rust API; allowing users to code up computational graphs and circuits from scratch in rust without having to go via python.","The MNIST inference example using ezkl as a library is contained in examples/conv2d_mnist. To run it:","We also provide an example which runs an MLP on input data with four dimensions. To run it:"]}],[{"l":"Python bindings"},{"l":"using ezkl from Python","p":["lets you use ezkl directly from Python. It also contains an export function to generate .onnx and .json input files that can be ingested by the ezkl cli or from Python. Here is colab notebook that shows how to produce and verify a proof from Python.","These Python bindings are developed in pyezkl.","When installing ezkl with pip, you may want to use a virtualenv. Some virtualenv management solutions for python includes venv, pipenv, conda, and poetry."]},{"l":"development","p":["Python bindings are built for ezkl using PyO3 and Maturin.","To test the development Python bindings you will need to install Python3.","Note, ezkl is only supported for Python=3.7, this installs the pyezkl build which contains Python specific functions that the Rust bindings on the main ezkl repository do not implement."]},{"l":"2. Install solc-select or svm-rs","p":["To run solidity and evm related functionality make sure to have solc available in your environment. We will need solc = 0.8.20, otherwise contracts will fail to compile. Otherwise, you are likely to encounter errors when dealing with solidity and evm related functionality that is used within ezkl.","It is recommended that you use solc-select if you prefer a python based management solution or svm if you prefer a rust based management solution. With a solidity version manager you are then able to change solidity versions in your environment easily."]},{"l":"3. Try out EZKL Examples in the repository with a Jupyter Notebook","p":["Clone the pyezkl repository.","Install jupyter and start the jupyter notebook","Navigate to the ezkl_demo.ipynb file which is located in the examples folder. It contains a minimal setup for running ezkl within python."]},{"l":"Developmental python bindings","p":["Setting up the development python bindings can be an involved process."]},{"l":"ezkl repository","p":["In the event that you may want to use the developmental bindings on the main ezkl repository, you can clone and build the main ezkl repository written in rust instead.","It's recommended that you set up a separate virtual environment for this.","Ensure that rust is installed in your local environment, this is needed by maturin/pyo3 to build the project.","Change the default toolchain to the nightly version as this is needed by some of the libraries used.","After which, you should be able to build via maturin build. This will build ezkl_lib not ezkl. ezkl_lib only includes the basic rust bindings without other Python functionality.","Once the build is complete, you will be able to find the built wheels within target/wheels. If your build is successful you should find a .whl file in the folder","Example:"]},{"l":"pyezkl repository","p":["If you would like to then use the development version of pyezkl with the developmental bindings at ezkl, you will need to setup pyezkl too.","Clone the pyezkl repository in a separate directory if you haven't done so already.","We will use poetry for the pyezkl repository. Install poetry by following the instructions provided.","You will also need to deactivate any existing virtualenv.","Once that is done setup the repository with poetry.","Navigate to the ezkl repository and install the wheel that you have built.","This will install the developmental ezkl_lib into the poetry environment. After which, you should be able to build the developmental ezkl library from the pyezkl repository.","If successful, you should be able to run python in your poetry environment and call the functions."]},{"l":"API Reference","p":["This reference details function, modules, and objects included in both ezkl and ezkl_lib. Note that ezkl is a superset of ezkl_lib so functions contained within ezkl_lib will be contained in ezkl."]},{"l":"ezkl"},{"l":"Utilities"},{"l":"export","p":["Description The export function is designed to export a PyTorch model in ONNX format for further use in different environments without Python dependencies. It also saves a sample input in JSON format. The function supports models with single input and output.","Parameters torch_model (required): This is the PyTorch model you want to export. It should be an instance of a class that inherits from torch.nn.Module.","input_shape (optional): This is a list of integers specifying the shape of the input tensor that the model expects. For example, for a 2D image, this might be [3, 224, 224] for three color channels (RGB) each of 224x224 pixels. This argument is required if input_array is not provided.","input_array (optional): This is a tensor that you can pass in if you want to specify the exact values of the input tensor. This should be a NumPy ndarray or something that can be converted into one (like a list or tuple of numbers). This argument is required if input_shape is not provided.","onnx_filename (optional): This is the name of the ONNX file that will be generated. The default value is \"network.onnx\".","input_filename (optional): This is the name of the JSON file that will be generated containing a sample input for the model. The default value is \"input.json\".","Returns The function does not have a return value. However, it writes two files to the disk:","An ONNX file containing the exported model. The name of the file is specified by the onnx_filename argument. A JSON file containing a sample input for the model. The name of the file is specified by the input_filename argument.","Notes The torch.onnx.export function is used to convert the PyTorch model to ONNX format. The function requires an example input tensor, which is used to run a forward pass of the model. This is needed because the ONNX exporter needs to know the shapes and data types of the tensors that flow through the model.","The exported ONNX model includes the weights of the trained model and also the network architecture. This means that the model can be used for inference in an environment where PyTorch is not installed.","The ezkl_lib.forward function is used for the forward operation to quantize inputs, there may be quantization errors associated with the quantization. Error metric functions can be used to compare the performance before and after quantization.","The function raises an error if neither input_shape nor input_array are provided, or if both are provided but input_shape doesn't match the shape of input_array."]},{"l":"ezkl_lib"},{"l":"Command Bindings"},{"l":"PyRunArgs","p":["allocated_constraints: This is an optional field that may contain a usize value representing the number of allocated constraints.","batch_size: This is a 32-bit unsigned integer that specifies the batch size for certain operations.","bits: This is a usize type and denotes the bit length for the snark.","Description","Fields","Fields marked with the #[pyo3(get, set)] attribute can be accessed (read or modified) directly from Python.","logrows: This is a 32-bit unsigned integer. This corresponds to the K value used in generating the SRS (Structured Reference String). You can obtain generated SRS from the powers of tau repository or call the gen_srs function for development use.","Methods The PyRunArgs struct has a new method that provides default instantiation. It initializes the fields with default values.","Notes For integer fields, you are able to use default Python integers.","pack_base: This is a 32-bit unsigned integer. This value refers to the packing base value to be used in the snark.","public_inputs: This is a boolean flag indicating whether inputs are public.","public_outputs: This is a boolean flag indicating whether outputs are public.","public_params: This is a boolean flag indicating whether parameters are public.","scale: This is a 32-bit unsigned integer which could be used to scale computation.","The PyRunArgs struct is a Python-friendly data structure that provides a set of arguments required to perform certain operations in a Rust environment. The structure is defined using the pyclass macro from the pyo3 library which makes it compatible with Python via PyO3/Maturin. The fields of PyRunArgs are accessible from Python, and can be both read and modified like Python classes.","There's also a conversion method provided for transforming a PyRunArgs instance to a RunArgs instance mainly used internally within the rust python bindings.","tolerance: This is an instance of the Tolerance enum, which defines the acceptable range of values for the snark computation."]},{"l":"table","p":["Description","The table function reads an ONNX model file, and then outputs the nodes of the model as a string.","Parameters model (required): This is a string representing the file path of the ONNX model to be loaded.","py_run_args (optional): This is an instance of PyRunArgs struct. If not provided, a new instance of PyRunArgs with default parameters will be created.","Returns The function returns the table formatted as a string in Python. It may throw an IOError if there are issues loading the model file.","Example The following is a Python example of how you might call this function:"]},{"l":"gen_srs","p":["Description The gen_srs function is designed to generate the Structured Reference String (SRS) for the KZGCommitmentScheme and save it to the specified path. The SRS is used in zk-SNARKs (Zero-Knowledge Succinct Non-Interactive Argument of Knowledge), to set up public parameters.","Important Note: The SRS generated here is not meant for production. You should use the powers of tau repo instead for production applications.","Parameters","params_path (required): This is a string representing the file path where the generated SRS will be saved.","logrows (required): This is an integer that represents the K value used in the SRS. More complex models will require more logrows in general. The downside of having more logrows is that the compute resources required will increase, increasing the time taken to generate proofs.","ezkl allows for the overflow of columns which would allow for more complex models to be computer with lesser logrows.","Returns The function returns nothing. Should it be successful a SRS file will be generated at the specified path.","Example","The following is a Python example of how you might call this function:"]},{"l":"forward","p":["Description","The forward function runs the forward pass operation for a specified model using the given data. It quantizes the input data, runs the model's forward pass with the quantized data, dequantizes the model output according to the scale factor, and saves the resulting data to a file.","Parameters","data (required): A string representing the file path of the data to be processed.","model (required): A string representing the file path of the model to be used for the forward pass operation.","output (required): A string representing the file path where the result of the forward pass operation will be saved.","py_run_args (optional): This is an instance of PyRunArgs struct. If not provided, a new instance of PyRunArgs with default parameters will be created.","Returns","The function returns nothing, but creates the output file at the provided output path. If there are errors reading and writing to files IOError will be raised.","Example The following is a Python example of how you might call this function:"]},{"l":"mock","p":["Description","The mock function creates a mock prover using the provided model and data. It processes the model, prepares public inputs, and uses a mock prover to verify the given setup. This function is typically used for testing and validation purposes.","Parameters data (required): A string representing the file path of the data to be used in the mock prover.","model (required): A string representing the file path of the model to be used by the mock prover.","py_run_args (optional): This is an instance of the PyRunArgs struct. If not provided, a new instance of PyRunArgs with default parameters will be created.","Returns","The function returns a boolean value. On successful execution, True or False if it does not. It may return an IOError if there are problems reading and writing to files, or a RuntimeError if there are problems constructing the circuit.","Example The following is a Python example of how you might call this function:"]},{"l":"setup","p":["Description","The setup function is used to set up the proving system. It processes a model, constructs a circuit, loads the parameters for the prover, creates and saves the prover and verifier keys, and finally saves the circuit parameters. You will have to run setup prior to running the prove step.","Parameters","model (required): A string representing the file path of the ONNX model to be processed and used to build the circuit.","vk_path (required): A string representing the file path where the verifier key will be saved.","pk_path (required): A string representing the file path where the prover key will be saved.","params_path (required): A string representing the file path where the parameters for the prover will be loaded from.","circuit_params_path (required): A string representing the file path where the circuit parameters will be saved.","py_run_args (optional): This is an instance of the PyRunArgs struct. If not provided, a new instance of PyRunArgs with default parameters will be created.","Returns","The function returns a boolean. If all the operations are successful, it will return True. If an error occurs at any stage, it will throw an IOError for errors associated with reading and writing or a RuntimeError associated with failure in the circuit setup.","Example","The following is a Python example of how you might call this function:"]},{"l":"prove","p":["Description","The prove function is used to execute a proving operation on a set of inputs. It prepares the data, loads the model circuit parameters, creates a circuit, prepares the public inputs, loads the parameters for the prover, loads the proving key, then based on the strategy, it creates a proof using a circuit and saves the proof.","Parameters","data (required): A string representing the file path of the data to be used in the proof.","model (required): A string representing the file path of the ONNX model.","pk_path (required): A string representing the file path where the prover key will be loaded from.","proof_path (required): A string representing the file path where the proof will be saved.","params_path (required): A string representing the file path where the parameters for the prover will be loaded from.","transcript (required): A string representing the type of transcript to be used. blake, poseidon, or evm is supported.","strategy (required): A string representing the strategy to be used for creating the proof. single or accum is supported.","circuit_params_path (required): A string representing the file path where the circuit parameters will be loaded from.","Returns","The function returns a boolean. If all the operations are successful, it will return True. If an error occurs at any stage, it will throw an IOError for errors associated with reading and writing or a RuntimeError associated with failure in the circuit creation.","Example"]},{"l":"verify","p":["Description","The verify function is used to verify a given proof. It loads the model circuit parameters, the parameters for the verifier, the proof, and the verifier key. Then it verifies the proof using a circuit.","Parameters","proof_path (required): A string representing the file path where the proof will be loaded from.","circuit_params_path (required): A string representing the file path where the circuit parameters will be loaded from.","vk_path (required): A string representing the file path where the verifier key will be loaded from.","params_path (required): A string representing the file path where the parameters for the verifier will be loaded from.","Returns","The function returns a boolean. If all the operations are successful, it will return True. If an error occurs at any stage, it will throw an IOError for errors associated with reading and writing or a RuntimeError associated with failure in the circuit creation.","Example"]},{"l":"aggregate","p":["Aggregation helps in making the overall proof size smaller, however, this comes at the expense of additional computational time required. Note that you will usually need more logrows for aggregation, so if proof aggregation is desired use a higher value of K for the logrows used.","aggregation_snarks (required): A list of strings representing the file paths where the proofs to be aggregated will be loaded from.","aggregation_vk_paths (required): A list of strings representing the file paths where the verifier keys will be loaded from.","check_mode (required): A string indicating whether checks will be performed. safe or unsafe is supported. If safety is not required in the case of development you may use unsafe which can provide some speedup.","circuit_params_paths (required): A list of strings representing the file paths where the circuit parameters will be loaded from.","Description","Example","logrows (required): An integer specifying the number of logrows available for compute, this will need to correspond to the logrows with the params_path.","Parameters","params_path (required): A string representing the file path where the parameters for the prover will be loaded from.","proof_path (required): A string representing the file path where the aggregated proof will be saved.","Returns","The aggregate function is used to create an aggregated proof from multiple proofs. It loads the parameters, then for each pair of proof and verifier key path, and circuit parameters path, it loads the model circuit parameters, the parameters for the prover, and the verifier key. Then it loads the proofs. Afterwards, it creates an aggregation circuit, the keys for it, creates a proof using the circuit, and saves the proof and the verifier key.","The function returns a boolean. If all the operations are successful, it will return True. If an error occurs at any stage, it will throw an IOError for errors associated with reading and writing or a RuntimeError associated with failure in the circuit creation.","transcript (required): A string representing the type of transcript to be used. blake, poseidon, or evm is supported.","vk_path (required): A string representing the file path where the aggregated verifier key will be saved."]},{"l":"verify_aggr","p":["Description","The verify_aggr function is used to verify an aggregated proof. It loads the parameters, the proof, and the verifier key, then uses these to verify the proof using the Accumulator Strategy. If the verification is successful, it returns true; otherwise, it returns false.","Parameters","proof_path (required): A string representing the file path where the aggregated proof will be loaded from.","vk_path (required): A string representing the file path where the verifier key will be loaded from.","params_path (required): A string representing the file path where the parameters for the verifier will be loaded from.","logrows (required): An integer specifying the number of logrows used for computation.","Returns","If the verification of the proof is successful, it will return True. If the proof cannot be verified or an error occurs at any stage, it will return False. If an error occurs at any stage, it will throw an IOError for errors associated with reading and writing or a RuntimeError associated with failure in the circuit creation.","Example"]},{"l":"create_evm_verifier","p":["Description","The create_evm_verifier function is used to generate an Ethereum Virtual Machine (EVM) compatible verifier. This function requires that the Solidity compiler (solc) is installed in the user's environment. You should use solc-select or svm-rs to help manage solc installed in the user's environment.","It first loads the model circuit parameters, the verifier parameters, and the verifier key. Using these, it generates the EVM compatible verifier. The verifier code is then saved as Yul and/or Solidity code.","Parameters","vk_path (required): A string representing the file path where the verifier key will be loaded from.","params_path (required): A string representing the file path where the parameters for the verifier will be loaded from.","circuit_params_path (required): A string representing the file path where the circuit parameters will be loaded from.","deployment_code_path (required): A string representing the file path where the yul deployment code for the verifier will be saved.","sol_code_path (optional): A string representing the file path where the Solidity code for the verifier will be saved.","Returns","If the EVM compatible verifier is successfully generated and saved, it will return True. If an error occurs at any stage, it will return an IOError or RuntimeError.","Example"]},{"l":"verify_evm","p":["Description","The verify_evm function verifies an Ethereum Virtual Machine (EVM) compatible proof. The function requires the Solidity compiler (solc) to be installed in the user's environment. The proof is loaded, and the deployment code is loaded from the given path. The proof is then verified using the EVM and optionally verified using Solidity if a path to the Solidity code is provided.","Parameters","proof_path (required): A string representing the file path where the proof will be loaded from.","deployment_code_path (required): A string representing the file path where the deployment code will be loaded from.","sol_code_path (optional): A string representing the file path where the Solidity code will be loaded from. If provided, the proof will also be verified using this Solidity code.","runs (optional): An integer > representing the number of times to run the Solidity verifier. This is only used if sol_code_path is provided.","Returns","If the EVM compatible proof is successfully verified, it will return True. If an error occurs at any stage, it will return an Err variant containing the Python error PyErr. If an error occurs at any stage, it will return an IOError or RuntimeError.","Example"]},{"l":"create_evm_verifier_aggr","p":["Description","The create_evm_verifier_aggr function creates an EVM compatible aggregate verifier. The function requires the Solidity compiler (solc) to be installed in the user's environment. The function loads the parameters and verifier key and generates the aggregate verifier. The generated verifier is then saved as Yul code, and optionally as Solidity code if a path to save the Solidity code is provided.","Parameters vk_path (required): A string representing the file path where the verifier key will be loaded from.","params_path (required): A string representing the file path where the parameters for the verifier will be loaded from.","deployment_code_path (required): A string representing the file path where the Yul deployment code for the verifier will be saved.","sol_code_path (optional): A string representing the file path where the Solidity code for the verifier will be saved.","Returns","The function returns a boolean. If the EVM compatible aggregate verifier is successfully created and saved, it will return True. If an error occurs at any stage, it will return a IOError or RuntimeError.","Example"]},{"l":"print_proof_hex","p":["Description","The print_proof_hex function loads a proof from a given file path and returns a string containing the hexadecimal representation of the proof.","Parameters","proof_path (required): A string representing the file path where the proof will be loaded from.","Returns","If the proof is successfully loaded and converted to a hexadecimal string, it will return a hex string in Python."]}],[{"l":"Compiling to WASI","p":["The cli can also be compiled for the wasm32-wasi target (browser bindings with wasm32-unknown-unknown under Tutorials/WASMTutorial). To do so, first ensure that wasm-pack is installed.","You can then run:","After adding the wasm32-wasi target, you can use wasm-pack to build ezkl for the wasm32-wasi target. The -Z flag helps us build unstable features.","Note: On Mac you may need to install llvm and clang using homebrew then explicitly set the CC and AR environment variables. For instance: AR=/opt/homebrew/opt/llvm/bin/llvm-ar CC=/opt/homebrew/opt/llvm/bin/clang wasm-pack build --bin ezkl --target wasm32-wasi -Z build-std=panic_abort,std. You can learn more about how to install these in the WASM tutorial.","You can then run the compiled .wasm file as you would the normal cli detailed above (just not the EVM related commands), by using wasmtime. This command runs ezkl help on wasmtime."]}],[{"l":"Benchmarks","p":["We include proof generation time benchmarks for some of the implemented layers including the affine, convolutional, and ReLu operations (more to come).","To run these benchmarks:","This may take a long time.","To run a specific benchmark append one of affine, cnvrl, relu to the command. You can then find benchmarks results and plots in target/criterion. Note that depending on the capabilities of your machine you may need to increase the target time on the Criterion config. For instance:"]}],[{"l":"About ONNX"},{"i":"what-is-onnx","l":"What is ONNX?","p":["ONNX (Open Neural Network Exchange) is an open-source standard for representing deep learning models. It was developed to facilitate interoperability between various deep learning frameworks, such as TensorFlow, PyTorch, and Caffe2. ONNX provides a common file format that allows models trained in one framework to be used in another framework for inference, without the need for model conversion."]},{"i":"why-do-we-use-onnx","l":"Why do we use ONNX?","p":["ONNX is used for several reasons:","Easy Integration: ONNX files are used in ezkl to generate zk-SNARKS from individual operations (e.g. ReLU, Sigmoid, Softmax). The ONNX format makes it straight-forward to parse and separate layers for generating individual circuits.","Interoperability: ONNX enables developers to train models in one deep learning framework and use them in another for inference, without the need for conversion. This eases the process of deploying models and allows developers to use the best tools for each part of the development process.","Portability: ONNX provides a standardized format for deep learning models, making it easier to share models across different platforms and devices.","Optimization: ONNX-compatible tools and libraries, such as ONNX runtimes, can provide optimizations for specific hardware, leading to improved performance.","Ecosystem support: Many popular deep learning frameworks and tools, like TensorFlow, PyTorch, and Microsoft's ONNX Runtime, support ONNX, providing a broad range of options for developers."]},{"l":"How to create an ONNX file","p":["Check out our pyezkl repository to find detailed steps on generating an ONNX file."]}],[{"l":"Library"},{"l":"Talks to watch","p":["Dante and Jason - Zero-Knowledge Machine Learning with EZKL in Autonomous Worlds","Jason Morton - What Is Unlocked by Practical Zero-Knowledge Proofs? | EDCON 2023 Montenegro","Zuzalu talks and panel - coming soon","ETH Denver talks - coming soon","Jason Morton - Zero-Knowledge Machine Learning 6 Jan 2023 | ZK SYMPOSIUM","Jason Morton - Zero-Knowledge Machine Learning 16 Nov 2022 | ZkProof Tel Aviv","Jason Morton - Zero-Knowledge Machine Learning 15 Sep 2022 | DEVCON Bogota","Jason Morton - Zero-Knowledge Machine Learning | Stanford Science of Blockchain Conference 2 Sept 2022"]},{"l":"Blog posts","p":["Constraint efficiency","Snarking a GPT"]},{"l":"EZKL in the press and blogs","p":["Spectral Finance: The State of Zero-Knowledge Machine Learning (zkML), 6 June 2023","Fortune: A brief history of zero-knowledge proofs, the buzzy mathematical technique that’s taken crypto by storm, 5 June 2023","1kx: zkML: Evolving the Intelligence of Smart Contracts Through Zero-Knowledge Cryptography, 23 May 2023","Fortune, 4 May 2023","a16z: Checks and balances: Machine learning and zero-knowledge proofs, 5 Apr 2023","SevenX Ventures: Balancing the Power of AI/ML: The Role of ZK and Blockchain","Coincu: ZKML: Breakthrough Technology With Growth Potential In Security Application","Worldcoin: An introduction to zero-knowledge machine learning (ZKML) 22 Feb 2023"]}],[{"l":"Security","p":["Zero knowledge machine learning, particularly in blockchain applications, is still a nascent field and should be used with caution. Because there have not yet been many production-ready projects, the potential attack vectors include both the usual and the mostly theoretical or unknown. ezkl has not been audited and we make no guarantees on its security.","Moreover, zkml is just one component of an overall cryptosystem, and that system as a whole has to be carefully thought out. Neural networks are not by themselves adequate hash functions; the whole point is that they are susceptible to differentiation!","Here are a few more things to worry about."]},{"i":"aiml-security","l":"AI/ML Security","p":["There are several types of adversarial attacks on neural networks. Gaussian Noise Injection, Data poisoning, Membership Inference Attacks(MIAs), and more are attack vectors that adversaries can use to corrupt your outputs. MIAs and others like it are especially hazardous when the aim of using zkml is to keep the model and its training data private.","Adversarial Training involves training your model with adversarial data so that edge cases are expected and accounted for. CleverHans is a useful tool for discovering potential vulnerabilities in your model. For best security results, have an idea of the overall threat model of your neural net and its potential inputs."]},{"l":"ZK Security","p":["The goal of zero knowledge proof systems is to construct complete, sound proofs. Completeness is the highly probable assurance that any valid proof will verify. Soundness is the quality of the verifier (or parties representing the verifier) knowing that if a proof passes, it is more than likely a true statement. In some cases, such as those in underconstrained circuits, bad proofs can be generated that fool the verifier into passing a false statement. In this case, the vulnerability is not in the machine learning model itself, but in the SNARK constructed by ezkl.","ezkl is a compiler, so eventually should be less susceptible to such issues than a hand-written circuit, but it is still under active development.","Please reach out directly to let us know of any soundess issues you encounter."]},{"l":"Fuzzing","p":["ezkl supports fuzzing over your model's edge inputs to test for potential vulnerabilities. Use your input.json and network.onnx files to run:","Be sure to replace num-runs with the amount of fuzz testing rounds you want to do along with other parameters you are using to generate your circuit.","Thank you for using ezkl; please contact us if you have any comments on this documentation."]}],[{"l":"FAQ"},{"i":"what-programming-languages-and-frameworks-does-ezkl-support","l":"What programming languages and frameworks does ezkl support?","p":["ezkl is a command line tool, and a library that can be used from Rust or Python. You may want to use Python to create a neural network and export it. Though ezkl is built with Rust, you do not need to use Rust except possibly for installation."]},{"i":"do-i-need-to-know-rust-before-getting-started-with-ezkl","l":"Do I need to know Rust before getting started with ezkl?","p":["No, Rust is not a requirement to use the library. As long as you have the ONNX file and proper input & output format of the model, you can use ezkl."]},{"l":"Technical"},{"i":"why-is-the-gen-srs-step-slow","l":"Why is the gen-srs step slow?","p":["Generating a structured reference string takes a considerable amount of time and memory. Make sure your machine has enough memory available and wait for the process to finish. Alternatively, download a pre-generated srs."]},{"i":"can-i-use-ezkl-with-other-machine-learning-frameworks-like-tensorflow-pytorch-or-scikit-learn","l":"Can I use ezkl with other machine learning frameworks like TensorFlow, PyTorch, or Scikit-learn?","p":["All ezkl requires is an onnx file and a JSON configuration of mock inputs and outputs of the neural network. At this time, it works best with PyTorch."]},{"i":"how-fast-is-ezkl","l":"How fast is ezkl?","p":["We believe that ezkl is the fastest zkml package available, and we are working hard every day to make it faster. Feel free to run cargo bench on your machine to see what the benchmarks are for your hardware."]},{"i":"do-i-need-to-deploy-a-verifier-smart-contract-to-use-ezkl","l":"Do I need to deploy a verifier smart contract to use ezkl?","p":["No, we recently integrated a WASM verifier that you can use to verify proofs from your web application. You can also use the EVM verifier to verify proofs locally, or the command line ezkl verify command."]},{"i":"errors","l":"Errors:"},{"i":"error-verifyerror","l":"Error: VerifyError","p":["A VerifyError is thrown when the Mock prover fails, often due to a mismatched shape problem in the model. Please verify that your input.json inputs and outputs match those of your .onnx file."]},{"i":"error-dimmismatch","l":"Error: DimMismatch","p":["A DimMismatch error is thrown when there is a mismatch in the lengths of the tensor operands during circuit construction."]},{"i":"error-lookupinstantiation","l":"Error: LookupInstantiation","p":["This error is thrown when there is an error during the creation of a lookup table"]},{"i":"error-tablealreadyassigned","l":"Error: TableAlreadyAssigned","p":["A TableAlreadyAssigned Error is thrown when ezkl attempts to initialize a lookup table that has already been initialized"]},{"i":"error-unsupportedop","l":"Error: UnsupportedOp","p":["An UnsupportedOp Error is thrown when there is an operation in the ONNX file that ezkl cannot yet handle. Please look at the supported operations under src/circuit/ops to get an idea of what operations ezkl can handle."]},{"i":"error-pyvalueerror","l":"Error: PyValueError","p":["This is a pyo3 error that occurs when a data type fails to be extracted from Python to Rust. Please make sure you are passing the correct data types when utilizing the python bindings."]},{"i":"error-invalidlookupinputs","l":"Error: InvalidLookupInputs","p":["InvalidLookupInputs is thrown when the wrong inputs were passed to a lookup node."]},{"i":"error-invaliddims","l":"Error: InvalidDims","p":["InvalidDims is thrown when there is a shape mismatch in circuit construction. Invalid dimensions were used for a node with the given index and description."]},{"i":"error-wrongmethod","l":"Error: WrongMethod","p":["This error means that the wrong method was called to configure a node with the given index and description"]},{"i":"error-missingnode","l":"Error: MissingNode","p":["MissingNode is thrown when a requested node is missing in the graph with the given index"]},{"i":"error-opmismatch","l":"Error: OpMismatch","p":["OpMismatch is thrown when an unsupported method was called on a node with the given index and description"]},{"i":"error-unsupportedop-1","l":"Error: UnsupportedOp","p":["UnsupportedOp is thrown when there is an operation in the onnx graph that isn't supported by ezkl"]},{"i":"error-missingparams","l":"Error: MissingParams","p":["MissingParams is thrown when a node has missing parameters; please check the parameters in your model's operations"]},{"i":"error-misformedparams","l":"Error: MisformedParams","p":["MisformedParams is thrown when a node has misformed parameters; the error can stem from erroneous padding height and width dimensions, wrong kernel / data format, dilations that are not uint type, and more."]},{"i":"error-visibility","l":"Error: Visibility","p":["This error is typically thrown when no public variables are passed to the circuit configuration function"]},{"i":"error-nonconstantdiv","l":"Error: NonConstantDiv","p":["ezkl only supports divisions by constants"]},{"i":"error-nonconstantpower","l":"Error: NonConstantPower","p":["ezkl only supports constant exponents"]},{"i":"error-rescalingerror","l":"Error: RescalingError","p":["This error is thrown when attempting to rescale inputs for an operation"]},{"i":"error-modelload","l":"Error: ModelLoad","p":["This error is thrown when a model fails to load; please check your onnx file for missing connections / unsupported layers. We suggest using Netron to view onnx files."]},{"i":"error-packingexponent","l":"Error: PackingExponent","p":["PackingExponent is thrown when the scale for packing tensor values is too large. Keep the exponent under the logarithm (with your chosen base) of i128::MAX(about 38 for base 10, about 88 for base e)."]}],[{"l":"WASM Tutorial","p":["wasm whirlwind"]},{"l":"Getting Started","p":[".gitignore","After this step, make sure you have access to the PATH for both clang and llvm. We'll be using environment variables such as CC=/opt/homebrew/opt/llvm/bin/clang for the remainder of the project.","Another thing we need before we get our .wasm file is LLVM. LLVM is a compiler tool that will help us use libraries that are essential for compiling our Rust ezkl code to a WASM binary fit for wasm32-unknown-unknown. You can get the latest release here(especially for Windows users) or install it with a package manager:","ezkl_lib_bg.wasm","ezkl_lib_bg.wasm.d.ts","ezkl_lib.d.ts","ezkl_lib.js","First, we need to add the wasm32-unknown-unknown target to our rustup configuration. wasm32-unknown-unknown is is a target for creating WebAssembly binaries. The wasm32 part represents the platform (WASM 32 bit in our case). The first unknown specifies the operating system we are building on. We want to build on any operating system since we're just building on browser. The second unknown refers to the target's standard library (Rust/C++ std), but with WASM, we won't be using one. We add this as a target with:","If something goes wrong, be certain that the paths to your llvm-ar and clang libraries are correct. Also make sure wasm-pack is installed and that your .cargo/config file in ezkl looks like this:","Install wasm-pack","It's useful to have a verifier on a blockchain. However, sometimes you just want to generate and verify proofs in the browser. Thankfully, ezkl supports a WASM environment that you can use to generate proofs and verify them in-browser. For those who are unfamiliar, here is a good resource on WASM and here you can find the functions we define for ezkl's WASM interface. Let's get started!","Linux","Mac: You can use Homebrew to install llvm. This library comes with clang, which we'll also need.","Make sure that you supply the correct paths for llvm-ar and clang (AR and CC). You can use brew info llvm on Mac or dpkg -L llvm for Linux.","Note that you should be on Rust's nightly release channel when interacting with ezkl.","Now, navigate to your fork or branch of ezkl and install the WASM server runner:","package.json","README.md","Remove the .gitignore file if you want to add pkg to your root git directory.","This command will generate a directory called pkg in our root ezkl directory. Within it, you will find these files:","With this, we're finally able to compile our .wasm file! You can do that with this command:"]},{"l":"Creating a frontend","p":["After this gives us our pk.key file, we will use that along with the input data(.json), the serialized circuit, the serialized circuit parameters, and our commitment scheme paramenters to trigger our prove_wasm function.","And thus, we have a WASM prover and verifier that you can use for your zkml project without having to worry about the blockchain! Feel free to check out the source code and build your own zkml applications with this simple interface. Thank you for reading and thank you for using ezkl.","At the end of the interaction, your screen should look something like:","circuit_params_ser: circuit parameters (circuit file generated from the last step)","circuit_params_ser: circuit parameters (circuit)","circuit_ser: circuit (network.onnx)","copy your new pkg directory into the project","create an index.html and paste this code in:","data: input data (input.json)","Finally, upload the corresponding files to each parameter.","From here, feel free to change the RunArgs as you please to make the best SNARK for your circuit. These are the arguments you see here. After you run the main function with cargo run --bin genscript, you will have a file called run_args.params. You can use this as the second parameter for gen_circuit_params_wasm.","Make a new directory for your project.","Now that we have the wasm-pack package, we can build a simple frontend that uses its exports to prove and verify models (we would love to see projects using this in more intricate ways). Here's what we'll do step-by-step:","params_ser: commitment scheme parameters (x.srs)","pk: proving key (pk.key)","proof_js: proof (network.proof)","Run a simple http server such as python3's:","RunArgs: RunArgs generated earlier in the tutorial","The ordering for Generate Circuit Params is:","The ordering for Generate Proving Key is:","The ordering for Generate Verifying Key is:","The ordering for Prove(from left to right) is:","The ordering for Verify(from left to right) is:","This script generates a simple HTML frontend with fields to pass in files for our input fields (we'll upload them from our ezkl directory). It also calls the ezkl_lib.js folder in our pkg to fetch the exported prove_wasm, verify_wasm, gen_circuit_params_wasm, gen_pk_wasm, and gen_vk_wasm functions.","This will prompt you to download a file called network.proof. network.proof is a binary file of the generated proof. Note that this step may take time. After network.proof has been downloaded, upload the file to the first value of the Verify function.","True or False should appear as the result for the Verify function.","verification","vk: verifier key (vk.key)","We will use the circuit file generated in this step to pass to our gen_pk_wasm function along with our commitment scheme parameters(x.srs) and serialized circuit.","We'll be using the ezkl library to pass in the serialized circuit(.onnx) and runargs to our gen_circuit_params_wasm function. In order to generate a serialized runargs file, you'll need to generate it. You can do this by adding a new Rust file to ezkl/src/bin(feel free to call it genscript.rs). Paste this code there:","When the network.proof file is created here, we will pass that along with the verify key and serialized circuit parameters to our verify_wasm function. It is important to note that you will have a lot of this information after you create a circuit with ezkl. Feel free to store them in your project (perhaps .gitignore-ing them). Now that we know what will happen, let's begin with the frontend."]}]]